# 模型的评估和选择
## 1. 测试集与训练集
### 1.1 训练集（Training Set）
- **定义**：用于模型训练过程的数据集，是模型学习数据规律、调整参数的核心依据。
- **数学表示**：若训练集包含\( M \)个样本实例，通常记为  
  \( D = \left\{ (x^{(j)}, y^{(j)}) \mid j=1,2, ..., M \right\} \)，  
  其中\( x^{(j)} \)为第\( j \)个样本的特征向量，\( y^{(j)} \)为该样本对应的真实标记（标签）。
- **核心用途**：为模型提供学习素材，使模型通过对训练集中样本规律的学习，确定自身的参数（如权重、偏置等），形成初步的预测能力。


### 1.2 测试集（Test Set）
- **定义**：用于评估训练后模型性能的数据集，专注于检验模型对“新样本”的适应能力。
- **数学表示**：若测试集包含\( N \)个测试样本实例，通常记为  
  \( T = \left\{ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ..., (x^{(N)}, y^{(N)}) \right\} \)，  
  其中\( x^{(i)} \)为第\( i \)个测试样本的特征向量，\( y^{(i)} \)为该测试样本的真实标记。
- **核心特性与用途**：
  - 必须与训练集**互斥**，即测试样本不能出现在训练集中，避免模型“记忆”测试样本导致评估失真；
  - 需从样本的**真实分布中独立同分布采样**，确保测试集能代表实际应用场景中的样本特征；
  - 用途是通过计算模型在测试集上的“测试误差”，近似推断模型在真实新样本上的“泛化误差”，判断模型的实际可用性。


### 1.3 划分目的与核心原则
- **核心目的**：准确估计模型的**泛化能力**。  
  机器学习的目标是获得“泛化误差小”的模型（即对新样本预测准确），而模型在训练集上的“经验误差（训练误差）”仅反映对训练数据的拟合程度，无法直接代表真实表现。通过划分训练集与测试集，可利用测试集模拟“新样本场景”，评估模型的泛化性能，避免仅依赖训练误差导致的误判。
- **关键原则**：
  - 测试集需“代表实际样本分布”：只有测试集的分布与真实场景样本分布一致，才能通过测试误差可靠近似泛化误差；
  - 样本占比合理：常规场景下，训练集占比通常为70%-80%，测试集占比20%-30%；大数据场景（百万级以上样本）中，测试集占比可降至1%甚至更低（如99.5%:0.25%:0.25%的Train:Val:Test划分），只要满足“代表性”即可。

## **2. 经验误差 vs 泛化误差**
| 名称 | 定义 | 别名 | 说明 |
|------|------|------|------|
| **经验误差** | 模型在**训练集**上的误差 | 训练误差（training error） | 反映模型对已见数据的拟合程度 |
| **泛化误差** | 模型在**新样本**（整体分布）上的误差 | 测试误差（testing error） | 真正关心的指标，**无法直接计算**，用测试误差近似 |

> **目标**：泛化误差小 → 模型对未知数据预测准确。

---

## **3. 过拟合与欠拟合**
| 现象 | 训练误差 | 测试误差 | 原因 | 解决方法 |
|------|----------|----------|------|----------|
| **欠拟合（Underfitting）** | 大 | 大 | 模型太简单、训练不足、特征不足 | 增加模型复杂度、添加特征、增加训练轮数 |
| **过拟合（Overfitting）** | 很小（接近0） | 很大 | 模型太复杂、记住噪声、数据量少 | Early Stopping、正则化、Dropout、数据增强、减少特征 |

### **过拟合三大原因**
1. **噪声数据误导**（绿色曲线拟合噪声点）
2. **训练数据量过少**（白马vs花狗，仅学到“纯白”）
3. **模型过于复杂**（高次多项式拟合简单关系）

### **处理过拟合常用方法**
- **Early Stopping**：验证集误差不再下降时停止
- **数据扩增**：增加样本，稀释噪声
- **正则化**：L1/L2限制参数大小
- **Dropout**：随机失活神经元，防止共适应
- **简化模型**：降低复杂度

### **处理欠拟合**
- 增加特征（组合特征、多项式特征）
- 减少正则化强度
- 增加模型复杂度（如加深网络）

---

## **4. 测试样本数据获取方法**
> **目标**：测试集应**独立同分布（i.i.d.）**于真实分布，且与训练集**互斥**  
> **建议比例**：大数据时代可为 `98%:1%:1%`（Train:Val:Test）

### **方法1：留出法（Hold-out）**
- 直接划分 \( D = S \cup T \)，\( S \cap T = \emptyset \)
- 保持**分层采样**（类别比例一致）
- 多次随机划分取平均
- 训练集建议占 **2/3 ~ 4/5**

### **方法2：k折交叉验证（k-fold CV）**
- 将 \( D \) 均分为 \( k \) 个互斥子集（分层采样）
- 每次用 \( k-1 \) 份训练，1 份测试 → 共 k 次
- 最终取 **k 次测试结果平均值**
- 常见：**5折、10折**

### **方法3：留一法（Leave-One-Out, LOO）**
- \( k = M \)（样本总数），每次留1个样本测试
- 优点：训练集最大，接近原分布
- 缺点：计算代价极高（M个模型）

#### **方法4：自助法（Bootstrap）**
- **有放回采样**生成 \( D' \)（大小仍为M）
- 未出现在 \( D' \) 中的样本（约36.8%）作测试集
- 优点：小数据集有效；适合集成学习
- 缺点：改变原始分布，引入偏差

> **实际使用建议**：
> - 数据量大 → 留出法
> - 数据量小 → 交叉验证或自助法
> - 交叉验证结果用于**评估**，最终模型用**全数据重新训练**

---

### **5. 模型性能度量**

#### **回归任务**
| 指标 | 公式 | 特点 |
|------|------|------|
| **均方误差 MSE** | \( E_{MSE} = \frac{1}{m}\sum (H(x_i) - y_i)^2 \) | 最常用，平方惩罚大误差 |
| **均方根误差 RMSE** | \( \sqrt{MSE} \) | 与原数据同量纲 |
| **平均绝对误差 MAE** | \( \frac{1}{m}\sum |H(x_i)-y_i| \) | 对异常值更鲁棒 |
| **平均绝对百分比误差 MAPE** | \( \frac{1}{m}\sum \left|\frac{H(x_i)-y_i}{y_i}\right| \) | 百分比形式，适合不同尺度 |

---

#### **分类任务**

##### **基本指标（二分类）**
| 真实 \ 预测 | 正例 | 反例 |
|-------------|------|------|
| **正例** | TP | FN |
| **反例** | FP | TN |

- **准确率（Accuracy）**：\( A = \frac{TP+TN}{TP+TN+FP+FN} \)
- **查准率（Precision）**：\( P = \frac{TP}{TP+FP} \) → “预测为正的中有多少是真的”
- **查全率（Recall）**：\( R = \frac{TP}{TP+FN} \) → “真实的正例中有多少被找出来”
- **F1-Score**：\( F1 = \frac{2PR}{P+R} \)（P和R的调和均值）

> **Fβ-Score**：\( F_\beta = \frac{(1+\beta^2)PR}{\beta^2 P + R} \)
> - β>1：更重视查全率
> - β<1：更重视查准率

##### **P-R 曲线**
- 横轴：查全率 R  
- 纵轴：查准率 P  
- 不同阈值 → 不同 (P,R) 点 → 连成曲线  
- **曲线越靠右上越好**，面积大表示性能好

##### **ROC 曲线与 AUC**
- 横轴：假正例率 \( FPR = \frac{FP}{FP+TN} \)
- 纵轴：真正例率 \( TPR = \frac{TP}{TP+FN} = R \)
- **对角线 = 随机猜测**
- **曲线越靠近左上角越好**
- **AUC**（曲线下面积）：0.5~1，越大越好

> **ROC vs P-R**：
> - ROC 关注整体排序能力（对阈值不敏感）
> - P-R 更关注正例预测准确性（类别不平衡时更敏感）

##### **多分类扩展**
- **宏平均（macro）**：先算每个类的指标，再平均（等权重）
- **微平均（micro）**：先累加TP/FP等，再整体计算（大类影响大）

---

### **6. 回归模型的泛化误差分解（Bias-Variance Decomposition）**

假设：
- \( y_D \)：带噪声的观测值
- \( y \)：真实值
- \( \bar{H}(x) \)：多次训练的期望预测
- \( H_{D_i}(x) \)：第 \( i \) 次训练的预测

#### **三项分解**：
\[
\underbrace{E(H_{D_i}(x) - y_D)^2}_{\text{泛化误差}} 
= \underbrace{Var(x)}_{\text{方差}} 
+ \underbrace{Bias^2(x)}_{\text{偏差平方}} 
+ \underbrace{\varepsilon^2}_{\text{噪声}}
\]

| 项 | 含义 | 影响因素 |
|----|------|----------|
| **偏差（Bias）** | 期望预测与真实值的差距 | 模型复杂度低 → 偏差大（欠拟合） |
| **方差（Variance）** | 不同训练集导致预测波动 | 数据少/模型复杂 → 方差大（过拟合） |
| **噪声（Noise）** | 数据本身不可避免的误差 | 任务难度，**不可控** |

#### **偏差-方差权衡图**
```
模型复杂度 ↑
训练误差 ↓
测试误差 → U形曲线（先降后升）
```

- 左：**高偏差，低方差** → 欠拟合
- 右：**低偏差，高方差** → 过拟合
- 中间：**最佳泛化点**

---

### **7. 总结：影响泛化性能的三大因素**
| 因素 | 作用 |
|------|------|
| **算法能力** | 决定偏差（Bias） |
| **数据充分性** | 决定方差（Variance） |
| **任务难度** | 决定噪声（Noise） |

---