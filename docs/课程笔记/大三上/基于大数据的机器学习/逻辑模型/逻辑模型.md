# 逻辑模型
## 思维导图
![exported_image.png](exported_image.png)
## 一、逻辑模型基础概念
1. 定义：通过逻辑表达式划分实例空间，使每个区隔内数据更一致，本质偏向规则系统，可解释性强。
2. 常见类型：概念学习、决策树模型、规则模型等。
3. 核心思想：源自计算机科学与工程，易转化为人类可理解的规则。

## 二、概念学习
### 1. 定义与核心逻辑
- 定义：利用布尔函数的输入输出训练样例，推断该布尔函数的归纳学习过程（狭义归纳学习）。
- 关键判定：实例\(x\)满足假设\(h\)的所有约束时，\(h(x)=1\)（分类为正例）。

### 2. 任务表述
- 已知条件：实例集合\(X\)（含6个属性及取值）、假设集合\(H\)（属性约束为“?”“∅”或特定值）、目标概念\(c\)（\(X \to \{0,1\}\)）、训练样例集合\(D\)（正例+反例）。
- 求解目标：在\(H\)中找到假设\(h\)，使对所有\(x \in X\)，\(h(x)=c(x)\)恒成立。

### 3. 假设空间
- 定义：全部可能的概念构成的集合，包含语法不同和语义不同的假设。
- 一般到特殊序：若对所有\(x \in X\)，\(h_k(x)=1\)可推出\(h_j(x)=1\)，则\(h_j \geq_g h_k\)（\(h_j\)更一般）。
- 一致与版本空间：假设\(h\)与训练样例\(X\)一致，即对所有\(<x,c(x)>\in X\)，\(h(x)=c(x)\)；版本空间\(VS_{H,X}\)是\(H\)中与\(X\)一致的所有假设子集。

### 4. 学习算法
#### （1）FIND-S算法
- 目标：寻找极大特殊假设。
- 步骤：初始化\(h\)为最特殊假设→遍历每个正例，若属性约束不满足正例则替换为更一般约束→输出最终假设。
- 特点：仅用正例学习，沿“特殊→一般”偏序链搜索，输出单一假设。

#### （2）候选消除算法
- 目标：找到与训练样例一致的所有假设（版本空间）。
- 核心逻辑：用正例泛化假设，用反例特化假设，通过边界集合\(S\)（最特殊假设）和\(G\)（最一般假设）表征版本空间。
- 基础方法（列表后消除）：初始化\(VS\)为\(H\)中所有假设→遍历样例，移除不满足\(h(x)=c(x)\)的假设→输出剩余假设。

## 三、决策树
### 1. 定义与特点
- 定义：树形结构分类/回归模型，通过逐层判断特征值到达叶子节点完成分类（非必为二叉树）。
- 表达能力：强于基于合取表达的概念学习，可转化为析取范式逻辑表达式。
- 核心策略：选择信息增益（或基尼指数）最大的特征构建节点，即优先选择分类价值最高的特征。

### 2. 关键度量指标
#### （1）熵与信息增益
- 熵（不确定性度量）：随机变量\(X\)的熵\(H(X)=-\sum_{i=1}^n p_i \log p_i\)；经验熵\(H(D)\)描述数据集分类不确定性。
- 条件熵：\(H(Y|X)=\sum_{i=1}^n p_i H(Y|X=x_i)\)，描述给定特征\(X\)后分类的不确定性。
- 信息增益：\(g(D,A)=H(D)-H(D|A)\)，衡量特征\(A\)降低分类不确定性的程度，值越大分类能力越强。

#### （2）基尼指数
- 定义：分类问题中，概率分布的基尼指数\(Gini(p)=1-\sum_{k=1}^K p_k^2\)，越大则随机性越强。
- 样本集合的基尼指数：\(Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)\)，用于选择最优切分特征和切分点。

### 3. 经典算法
#### （1）ID3算法（分类树）
- 核心逻辑：以信息增益最大为准则选择特征，递归构建决策树。
- 步骤：若样本全属同一类或无特征可选，返回单节点树→计算特征信息增益，选择最优特征→按特征取值划分样本，递归构建子树→若信息增益小于阈值，返回单节点树（标记为样本数最多的类）。

#### （2）CART树（分类与回归树）
- 分类树：以基尼指数最小为准则选择特征和切分点，构建二叉树。
- 回归树：以均方误差最小为准则划分样本，叶子节点输出为对应区域样本的均值，模型表达式\(f(x)=\sum_{m=1}^M c_m I(x \in R_m)\)。
- 构建步骤：遍历特征和切分点→选择最优切分（最小化均方误差/基尼指数）→递归划分样本→剪枝优化（基于验证集或正则化项）。

### 4. 优化与扩展
- 过拟合处理：剪枝（基于验证集泛化误差或正则化项\(C(T)=\sum_{t=1}^{|T|} N_t H_t(T)+\alpha|T|\)）。
- 特征选择改进：C4.5算法用信息增益比替代信息增益，避免偏向取值多的特征。
- 任务扩展：从分类任务延伸到回归任务，核心是将输出从离散类别改为连续值（区域均值）。

## 四、核心小结
1. 关键概念：理解假设空间、版本空间的定义，区分假设与概念的差异。
2. 学习逻辑：概念学习通过“特殊→一般”或“一般→特殊”搜索假设空间；决策树通过分步最优策略（最大化信息增益/最小化基尼指数）构建模型。
3. 任务延伸：掌握从分类问题（ID3、CART分类树）到回归问题（CART回归树）的逻辑模型适配方法。